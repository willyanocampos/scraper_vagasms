# üó∫Ô∏è Scrapper Vagas MS

**Sistema Inteligente de Coleta e An√°lise de Vagas de Emprego em Mato Grosso do Sul**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Status](https://img.shields.io/badge/Status-Ativo-green.svg)](https://github.com/seu-usuario/scrapper-vagasms)
[![Licen√ßa](https://img.shields.io/badge/Licen√ßa-MIT-yellow.svg)](LICENSE)

## üìã Sobre o Projeto

O **Scrapper Vagas MS** √© uma solu√ß√£o completa para coleta automatizada, an√°lise e visualiza√ß√£o de oportunidades de emprego espec√≠ficas do estado de Mato Grosso do Sul. O sistema combina web scraping inteligente com uma interface desktop moderna e mapas interativos para fornecer insights valiosos sobre o mercado de trabalho regional.

### üéØ Objetivos Principais

- ‚úÖ **Automatizar** a coleta de vagas de emprego de m√∫ltiplas fontes
- ‚úÖ **Filtrar** inteligentemente oportunidades espec√≠ficas de MS
- ‚úÖ **Visualizar** dados geogr√°ficos em mapas interativos
- ‚úÖ **Analisar** tend√™ncias do mercado de trabalho regional
- ‚úÖ **Facilitar** a descoberta de oportunidades pelos usu√°rios

## üöÄ Funcionalidades Principais

### üîç Web Scraping Inteligente
- **Multi-Empresa**: Suporte a 141+ empresas com portais pr√≥prios
- **Detec√ß√£o Autom√°tica**: Identifica√ß√£o inteligente de vagas MS
- **Processamento Paralelo**: Extra√ß√£o otimizada com multi-threading
- **Valida√ß√£o Geogr√°fica**: Sistema robusto de verifica√ß√£o de localiza√ß√£o
- **M√∫ltiplas Estrat√©gias**: Suporte a Gupy, sites propriet√°rios e APIs

### üìä Interface Desktop Moderna
- **Design Responsivo**: Interface customtkinter elegante
- **Gr√°ficos Interativos**: Visualiza√ß√µes matplotlib integradas
- **Filtros Avan√ßados**: Sistema de busca e filtragem poderoso
- **Exporta√ß√£o de Dados**: Suporte a m√∫ltiplos formatos (CSV, JSON, Excel)
- **Tema Escuro/Claro**: Interface adapt√°vel √†s prefer√™ncias

### üó∫Ô∏è Mapas Interativos
- **Leaflet Integration**: Mapas web responsivos e interativos
- **Clustering Inteligente**: Agrupamento autom√°tico de marcadores
- **Popups Informativos**: Detalhes completos das vagas por localiza√ß√£o
- **Cores por Setor**: Sistema visual intuitivo por √°rea de atua√ß√£o
- **Estat√≠sticas em Tempo Real**: M√©tricas atualizadas dinamicamente

### üé® Sistema de Filtros
- **Por Empresa**: Filtros espec√≠ficos por empregador
- **Por Localiza√ß√£o**: Busca geogr√°fica precisa (28 cidades)
- **Por Setor**: Classifica√ß√£o por √°rea de atua√ß√£o
- **Por Tipo**: Contrato, remoto, presencial, h√≠brido
- **Por Data**: Per√≠odo de coleta personaliz√°vel
- **Busca Textual**: Pesquisa inteligente em t√≠tulos e descri√ß√µes

## üèóÔ∏è Arquitetura do Sistema

```
scrapper_vagasms/
‚îú‚îÄ‚îÄ üìÅ Core Sistema
‚îÇ   ‚îú‚îÄ‚îÄ unified_ms_job_scraper.py    # üéØ Motor principal de scraping
‚îÇ   ‚îú‚îÄ‚îÄ ms_jobs_desktop.py           # üñ•Ô∏è Interface desktop
‚îÇ   ‚îî‚îÄ‚îÄ interactive_map_widget.py    # üó∫Ô∏è Widget de mapas
‚îú‚îÄ‚îÄ üìÅ Dados e Configura√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ accurate_ms_map_data.py      # üìç Dados geogr√°ficos MS
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_filters.py          # üîç Sistema de filtros
‚îÇ   ‚îî‚îÄ‚îÄ data/                        # üìä Dados de empresas
‚îú‚îÄ‚îÄ üìÅ Componentes de Mapa
‚îÇ   ‚îú‚îÄ‚îÄ map_components/              # üß© M√≥dulos especializados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py        # ‚öôÔ∏è Processamento de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ map_renderer.py          # üé® Renderiza√ß√£o de mapas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ popup_generator.py       # üí¨ Gera√ß√£o de popups
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ style_manager.py         # üé≠ Gerenciamento de estilos
‚îî‚îÄ‚îÄ üìÅ Utilit√°rios
    ‚îî‚îÄ‚îÄ logs/                        # üìù Logs do sistema
```

## üíª Tecnologias Utilizadas

### üêç Backend & Scraping
- **Python 3.9+** - Linguagem principal
- **Selenium WebDriver** - Automa√ß√£o de navegadores
- **BeautifulSoup4** - Parser HTML/XML
- **pandas** - Manipula√ß√£o e an√°lise de dados
- **requests/aiohttp** - Cliente HTTP s√≠ncrono/ass√≠ncrono
- **psutil** - Monitoramento de sistema
- **concurrent.futures** - Processamento paralelo

### üñ•Ô∏è Interface Desktop
- **customtkinter** - Interface moderna
- **matplotlib** - Gr√°ficos e visualiza√ß√µes
- **tkinter** - Interface base do Python
- **geopandas** *(opcional)* - Dados geogr√°ficos avan√ßados

### üåê Mapas e Visualiza√ß√£o
- **Leaflet.js** - Biblioteca de mapas web
- **folium** - Interface Python para Leaflet
- **Marker Cluster** - Agrupamento de marcadores
- **HTML5/CSS3/JavaScript** - Frontend web

## üõ†Ô∏è Instala√ß√£o e Configura√ß√£o

### üìã Pr√©-requisitos

- **Python 3.9 ou superior**
- **Google Chrome ou Chromium** (para Selenium)
- **Git** (para clonagem do reposit√≥rio)

### üîß Instala√ß√£o Passo a Passo

1. **Clone o reposit√≥rio**
   ```bash
   git clone https://github.com/seu-usuario/scrapper-vagasms.git
   cd scrapper-vagasms
   ```

2. **Instale as depend√™ncias do sistema**
   ```bash
   # Ubuntu/Debian
   sudo apt update
   sudo apt install python3-psutil python3-pip chromium-browser
   
   # CentOS/RHEL/Fedora
   sudo dnf install python3-psutil python3-pip chromium
   
   # Windows (via Chocolatey)
   choco install python googlechrome
   ```

3. **Crie e ative o ambiente virtual**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # Linux/Mac
   # ou
   .venv\Scripts\activate.bat  # Windows
   ```

4. **Instale depend√™ncias Python**
   ```bash
   pip install -r requirements.txt
   # ou instale manualmente:
   pip install selenium beautifulsoup4 pandas requests customtkinter matplotlib folium psutil aiohttp
   ```

5. **Configure as vari√°veis de ambiente**
   ```bash
   cp .env.example .env
   # Edite .env conforme necess√°rio
   ```

6. **Instale depend√™ncias opcionais** *(para recursos avan√ßados)*
   ```bash
   # Para an√°lise geogr√°fica avan√ßada
   pip install geopandas
   
   # Para performance adicional
   pip install lxml html5lib
   ```

### ‚öôÔ∏è Configura√ß√£o Avan√ßada

#### Arquivo `.env` Principal
```bash
# Performance do Scraper
SCRAPER_MAX_WORKERS=6
SCRAPER_RATE_LIMIT=1.0
SCRAPER_TIMEOUT=30

# Diret√≥rios de Output
SCRAPER_OUTPUT_DIR=output
SCRAPER_LOG_DIR=logs

# Funcionalidades
SCRAPER_ENABLE_ASYNC=true
SCRAPER_ENABLE_CACHING=true
SCRAPER_VERBOSE_LOGGING=false
```

## üöÄ Como Usar

### üéØ Execu√ß√£o do Scraper Principal

```bash
# Executar scraper completo
python3 unified_ms_job_scraper.py

# Executar com configura√ß√µes espec√≠ficas
python3 unified_ms_job_scraper.py --max-workers 8 --timeout 45

# Executar em modo verbose
python3 unified_ms_job_scraper.py --verbose

# Executar para empresas espec√≠ficas
python3 unified_ms_job_scraper.py --companies "JBS,COPASUL,Vale"
```

### üñ•Ô∏è Interface Desktop

```bash
# Iniciar aplica√ß√£o desktop
python3 ms_jobs_desktop.py

# Funcionalidades dispon√≠veis:
# ‚Ä¢ Visualizar vagas coletadas
# ‚Ä¢ Aplicar filtros avan√ßados
# ‚Ä¢ Gerar gr√°ficos estat√≠sticos
# ‚Ä¢ Exportar dados
# ‚Ä¢ Abrir mapas interativos
```

### üó∫Ô∏è Gera√ß√£o de Mapas

```bash
# Gerar mapa interativo standalone
python3 interactive_map_widget.py

# Op√ß√µes de customiza√ß√£o:
# ‚Ä¢ Escolher dados de entrada
# ‚Ä¢ Definir filtros geogr√°ficos
# ‚Ä¢ Configurar estilos visuais
# ‚Ä¢ Exportar HTML
```

## üìä Dados Suportados

### üè¢ Empresas Cobertas
- **141+ empresas** com portais pr√≥prios em MS
- **Setores diversos**: Agroneg√≥cio, Frigor√≠fico, Minera√ß√£o, Servi√ßos, Tecnologia
- **Cobertura geogr√°fica**: 28 cidades de MS
- **Tipos de portal**: Gupy, plataformas propriet√°rias, sites corporativos

### üìç Cidades Cobertas
```
Campo Grande    ‚Ä¢ Dourados        ‚Ä¢ Tr√™s Lagoas    ‚Ä¢ Corumb√°
Ponta Por√£      ‚Ä¢ Navira√≠         ‚Ä¢ Nova Andradina ‚Ä¢ Maracaju  
Sidrol√¢ndia     ‚Ä¢ Caarap√≥         ‚Ä¢ Aquidauana     ‚Ä¢ Parana√≠ba
Chapad√£o do Sul ‚Ä¢ Coxim           ‚Ä¢ Miranda        ‚Ä¢ Bonito
Jardim          ‚Ä¢ Iguatemi        ‚Ä¢ Itaquira√≠      ‚Ä¢ √Ågua Clara
... e mais 8 cidades
```

### üíº Informa√ß√µes Coletadas
- **T√≠tulo da vaga** e descri√ß√£o completa
- **Empresa** e setor de atua√ß√£o
- **Localiza√ß√£o** precisa (cidade/regi√£o)
- **Tipo de contrato** (CLT, PJ, Est√°gio, etc.)
- **Modalidade** (Presencial, Remoto, H√≠brido)
- **Data de coleta** e validade
- **Link direto** para candidatura
- **Requisitos** e benef√≠cios *(quando dispon√≠vel)*

## üìà Exemplos de Uso

### üîç Cen√°rio 1: An√°lise de Mercado Regional
```python
# Coletar dados de todas as empresas de agroneg√≥cio
python3 unified_ms_job_scraper.py --sector "Agroneg√≥cio" --region "Centro-Oeste MS"

# Analisar na interface desktop
python3 ms_jobs_desktop.py
# ‚Üí Aplicar filtros por setor
# ‚Üí Visualizar distribui√ß√£o geogr√°fica
# ‚Üí Gerar relat√≥rios estat√≠sticos
```

### üéØ Cen√°rio 2: Busca Personalizada
```python
# Buscar vagas espec√≠ficas de TI
python3 unified_ms_job_scraper.py --keywords "desenvolvedor,programador,analista sistemas"

# Filtrar resultados
# ‚Üí Remoto: Trabalho √† dist√¢ncia
# ‚Üí Campo Grande: Localiza√ß√£o espec√≠fica
# ‚Üí √öltimos 7 dias: Per√≠odo recente
```

### üó∫Ô∏è Cen√°rio 3: Visualiza√ß√£o Geogr√°fica
```python
# Gerar mapa de densidade de vagas
python3 interactive_map_widget.py --input "output/vagas_ms_latest.csv"

# Recursos do mapa:
# ‚Üí Clustering por densidade
# ‚Üí Filtros por empresa
# ‚Üí Popups com detalhes
# ‚Üí Estat√≠sticas por regi√£o
```

## üîß Solu√ß√£o de Problemas

### ‚ùó Problemas Comuns

#### **ChromeDriver n√£o encontrado**
```bash
# Ubuntu/Debian
sudo apt install chromium-chromedriver

# Manual
wget https://chromedriver.chromium.org/
sudo mv chromedriver /usr/local/bin/
```

#### **Erro de permiss√£o psutil**
```bash
# Linux
sudo apt install python3-psutil

# Ou alternativa via pip
pip install --user psutil
```

#### **Timeout em sites lentos**
```bash
# Aumentar timeout no .env
SCRAPER_TIMEOUT=60
SCRAPER_RATE_LIMIT=2.0
```

#### **Interface n√£o carrega**
```bash
# Instalar depend√™ncias de GUI
sudo apt install python3-tk python3-dev

# Atualizar customtkinter
pip install --upgrade customtkinter
```

### üêõ Debug e Logs

```bash
# Habilitar logs detalhados
export SCRAPER_VERBOSE_LOGGING=true

# Verificar logs
tail -f logs/scraper_$(date +%Y%m%d).log

# Testar conex√µes
python3 -c "from selenium import webdriver; print('Selenium OK')"
```

## ü§ù Contribui√ß√£o

### üìù Como Contribuir

1. **Fork** o reposit√≥rio
2. **Crie** uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. **Push** para a branch (`git push origin feature/AmazingFeature`)
5. **Abra** um Pull Request

### üéØ √Åreas de Contribui√ß√£o

- **üîç Novos Scrapers**: Adicionar suporte a mais empresas/plataformas
- **üé® Interface**: Melhorar UX/UI da aplica√ß√£o desktop
- **üìä An√°lises**: Implementar novas visualiza√ß√µes e insights
- **üó∫Ô∏è Mapas**: Adicionar recursos geogr√°ficos avan√ßados
- **üîß Performance**: Otimizar velocidade e consumo de recursos
- **üìö Documenta√ß√£o**: Melhorar docs e exemplos

### üìã Padr√µes de C√≥digo

- **PEP 8** para formata√ß√£o Python
- **Type hints** obrigat√≥rios em fun√ß√µes p√∫blicas
- **Docstrings** detalhadas para classes e m√©todos
- **Testes unit√°rios** para funcionalidades cr√≠ticas
- **Logs estruturados** para debugging

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a **MIT License** - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üÜò Suporte

### üìû Canais de Suporte

- **Issues**: [GitHub Issues](https://github.com/seu-usuario/scrapper-vagasms/issues)
- **Discuss√µes**: [GitHub Discussions](https://github.com/seu-usuario/scrapper-vagasms/discussions)
- **Email**: seu.email@exemplo.com

### ‚ùì FAQ

**P: O scraper funciona 24/7?**  
R: Sim, mas recomenda-se intervalos para respeitar rate limits dos sites.

**P: Posso adicionar mais empresas?**  
R: Sim! Edite o arquivo `data/json_portais_carreiras_ms.json`.

**P: Os mapas funcionam offline?**  
R: N√£o, requerem conex√£o para carregar tiles do Leaflet.

**P: H√° limites de coleta?**  
R: O sistema respeita robots.txt e implementa rate limiting √©tico.

---

## üìä Estat√≠sticas do Projeto

- **üìÅ Arquivos Python**: 6 principais + 5 m√≥dulos auxiliares
- **üìè Linhas de C√≥digo**: ~4.000+ linhas
- **üè¢ Empresas Suportadas**: 141+ portais
- **üìç Cidades Cobertas**: 28 cidades MS
- **üéØ Precis√£o Geogr√°fica**: >95% para localiza√ß√£o MS

---

**Desenvolvido com ‚ù§Ô∏è para o mercado de trabalho de Mato Grosso do Sul**

*√öltima atualiza√ß√£o: Setembro 2024*